# Florence_2

You can access the [Florence_2](https://huggingface.co/spaces/Itanutiwari527/Florence-2-demo) model hosted on Hugging Face spaces.

Image analysis on Florence Model.

This repo contains analysis of Florence model on MS Coco Dataset (1k images from 2k17 val datset). Object Detection and Caption generation was tested. 

## Object Detection

Analysis was made for Bounding boxes.

| Metric    | Value |
|-----------|-------|
| Accuracy  | 0.542 |
| Precision | 0.757 |
| Recall    | 0.656 |


## Caption Generation

Caption generated by model was compared with the ground truth captions. Embeddings of predicted and ground truth were generated using Sentence bert then thresholds were used to estimate a match.


| Similarity Threshold | Accuracy |
|----------------------|----------|
| 0.50                 | 0.990    |
| 0.60                 | 0.957    |
| 0.70                 | 0.836    |
| 0.75                 | 0.732    |
| 0.80                 | 0.587    |
| 0.90                 | 0.219    |

## Files 
1. ms_coco_datadownload.ipynb - To download and store data in a particular format.
    * I have downloaded 1000 images from the set "coco-2017" and applied florence_2 model on Object Detection subtask, stored the detected objects in folders ground_truth and model_pred for further analysis.

2. Analysis_of_correspondingobj.ipynb  - Calculating the accuracy, precision and recall for object detection task.
    * I have taken the ground_truth and model_pred folders and calculated IOU(intrsection over union) scores for identifying model predictions corresponding to the ground truth labels. Processed with a threshold of 0.5 and displayed the reults TP, FP, F, precision,	recall,	accuracy and f1_score in a dataframe. Calculated overall accuracy, precision and recall.

3. cococaptions.ipynb and sorted_captions_val2017.csv - Files to generate and store Ground Truth captions.
    * Taken the captions from file "captions_val2017.json" and stored image_id and five ground truth captions per image into "sorted_captions_val2017" file.

4. Florence 2 analysis. pdf - Demonstration of few results comparing model predictions(GT object detection marked in red bbox and predicted in orange bbox)
    * A presentation on how the ground truth objects are detected and how the model is identifying objects.Latter image captions and model generated captions on a few images selected from the dataset.

5. ground_truth and model_pred folders to store the calculated bboxes generated from the ms_coco_datadownload.ipynb file.

6. Visualizing_output - File to open and view the detected objects in given dataset alongwith model's predictions.
    * File to demonstrate and visualize comparison between ground truth and model's predicted objects.

7. captions_val2017.json - Ground Truth captions. 

8. Image_captions_model.ipynb and generated_captions_model.csv
File to generate captions from model and storing captions in a .csv file.

9. matching_captions.ipynb - using BERT sentence transformer model('all-MiniLM-L6-v2') to calculate accuracy scores.


